{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7b1705-074d-4587-8818-9730350b90e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dropbox in /opt/anaconda3/lib/python3.9/site-packages (11.27.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.9/site-packages (from dropbox) (1.16.0)\n",
      "Requirement already satisfied: stone>=2.* in /opt/anaconda3/lib/python3.9/site-packages (from dropbox) (3.3.1)\n",
      "Requirement already satisfied: requests>=2.16.2 in /opt/anaconda3/lib/python3.9/site-packages (from dropbox) (2.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.16.2->dropbox) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.16.2->dropbox) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.16.2->dropbox) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.16.2->dropbox) (2.0.4)\n",
      "Requirement already satisfied: ply>=3.4 in /opt/anaconda3/lib/python3.9/site-packages (from stone>=2.*->dropbox) (3.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c28d5f7-f51a-4966-9fa2-7bf5dcd3604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dropbox\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Time Series analysis\n",
    "# https://www.machinelearningplus.com/time-series/time-series-analysis-python/\n",
    "from dateutil.parser import parse\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "plt.rcParams.update({'figure.figsize': (10, 7), 'figure.dpi': 120})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c5b59078-1566-4850-a70c-2d7f43750078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - - - other file\n",
      "/myla data identified subset/reference only\n",
      " - - - grades file\n",
      " - - - student course file\n",
      " - - - event log file\n",
      " - - - grades file\n",
      " - - - grades file\n",
      " - - - grades file\n",
      " - - - event log file\n",
      " - - - student course file\n",
      " - - - event log file\n",
      " - - - event log file\n",
      " - - - student course file\n",
      " - - - student course file\n",
      " - - - course map file\n",
      " - - - other file\n",
      "/myla data identified subset/winter2019_course_map.csv\n",
      " - - - student map file\n",
      "\n",
      "BREAK\n"
     ]
    }
   ],
   "source": [
    "# Important:\n",
    "# 1. Save a copy of this script to your own Google Drive\n",
    "# 2. Genereate your own DROPBOX_TOKEN,\n",
    "#    NEVER share it with others or check into version control systems like GitHub\n",
    "dbx = dropbox.Dropbox('nsLc8YQnhKQAAAAAAAAAAUhNcy49b5vPam_1YlmP_16UdsYds9pORaTbOpGQ-XMy') ## REPLACE TOKEN HERE\n",
    "dbx.users_get_current_account()\n",
    "data_blank = [[]]\n",
    "df_main = pd.DataFrame(data_blank)\n",
    "df_logs = pd.DataFrame(data_blank)\n",
    "df_grades = pd.DataFrame(data_blank)\n",
    "\n",
    "# define function to parse term code from file path string\n",
    "def set_term_code(file_path,year) :\n",
    "    term_code = ''\n",
    "    if 'fall' in file_path :\n",
    "        term_code = year + '10'\n",
    "        term_code = int(term_code) + 100\n",
    "        term_code = str(term_code)\n",
    "    elif 'winter' in file_path :\n",
    "        term_code = year + '20'\n",
    "    else :\n",
    "        print('Error reading term description from file path')\n",
    "    return term_code\n",
    "\n",
    "# def get_term_desc(term_code) :\n",
    "#     int(term_code)\n",
    "\n",
    "for entry in dbx.files_list_folder('/MyLA Data Identified Subset').entries:\n",
    "    file_path = entry.path_lower\n",
    "    \n",
    "    \n",
    "    \n",
    "    # check for course id map file name to save dataframe for later joining\n",
    "    if 'course_map' in file_path and 'winter2019' in file_path :\n",
    "        _, res = dbx.files_download(file_path)\n",
    "        with io.BytesIO(res.content) as stream:\n",
    "#             df = pd.read_csv(stream, header=None)\n",
    "            df = pd.read_csv(stream)\n",
    "        df_cmap = df\n",
    "        print(' - - - course map file')\n",
    "        df_cmap = df_cmap.rename({'Canvas Course ID': 'Canvas CID','Canvas Course Name':'Canvas CName'}\n",
    "                                 , axis='columns')\n",
    "        df_cmap['Canvas CID'] = df_cmap['Canvas CID'].astype(str)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # check for student id map file name to save dataframe for later joining\n",
    "    if 'student_map' in file_path :\n",
    "        _, res = dbx.files_download(file_path)\n",
    "        with io.BytesIO(res.content) as stream:\n",
    "#             df = pd.read_csv(stream, header=None)\n",
    "            df = pd.read_csv(stream)\n",
    "        df_smap = df\n",
    "        print(' - - - student map file')\n",
    "#         print(file_path)\n",
    "        df_smap.columns = ['User ID','Uniqname']\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    # check for student grades data and compile into one frame\n",
    "    elif 'canvasgrades' in file_path :\n",
    "        _, res = dbx.files_download(file_path)\n",
    "        with io.BytesIO(res.content) as stream:\n",
    "            df = pd.read_csv(stream)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        year_code = file_path[int(file_path.find('.csv'))-4:int(file_path.find('.csv'))]\n",
    "        print(' - - - grades file')\n",
    "#         print(file_path)\n",
    "        df_term = set_term_code(file_path,year_code)\n",
    "#         print('Term is: ', df_term)\n",
    "        df['Term Code'] = df_term\n",
    "        \n",
    "        df = df.rename({'Canvas_course_id': 'Canvas CID','final_score':'Final Grade',\n",
    "                        'unique_name':'Uniqname'}, axis='columns')\n",
    "        df['Canvas CID'] = df['Canvas CID']%1000000\n",
    "        df['Canvas CID'] = df['Canvas CID'].astype(str)\n",
    "        df_grades = pd.concat([df_grades,df])\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    # check for student course roster data file name to compile course headcount main dataframe\n",
    "    elif 'myla_student_data' in file_path :\n",
    "        _, res = dbx.files_download(file_path)\n",
    "        with io.BytesIO(res.content) as stream:\n",
    "            df = pd.read_csv(stream)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        year_code = file_path[int(file_path.find('_withcanvas'))-4:int(file_path.find('_withcanvas'))]\n",
    "        print(' - - - student course file')\n",
    "#         print(file_path)\n",
    "        df_term = set_term_code(file_path,year_code)\n",
    "#         print('Term is: ', df_term)\n",
    "        df['Term Code'] = df_term\n",
    "        if df_term == '201920' :\n",
    "            df = df.rename({'Canvas Course': 'CanvasCourseName'}, axis='columns')\n",
    "            df['CanvasCourseID_short'] = ' '\n",
    "        if df_term == '202020' or df_term == '202110' :\n",
    "            df = df.rename({'CanvasCousreName': 'CanvasCourseName'}, axis='columns')\n",
    "        df = df[['Campus ID', 'Sex', 'International or Domestic','Acad Level BOT', 'Cum GPA', \n",
    "                   'CanvasCourseName', 'CanvasCourseID_short', 'Term Code']]\n",
    "        df = df.rename({'CanvasCourseName': 'Canvas CName','International or Domestic':'Intl/Dom',\n",
    "                           'Acad Level BOT':'Class Level','CanvasCourseID_short':'Canvas CID',\n",
    "                           'Campus ID':'Uniqname'}, axis='columns')\n",
    "        df['Canvas CID'] = df['Canvas CID'].astype(str)\n",
    "        df['Uniqname'] = df['Uniqname'].str.lower()\n",
    "        df_main = pd.concat([df_main,df])\n",
    "#         print(df.head(5))\n",
    "#         print(df.columns)\n",
    "    \n",
    "        \n",
    "    # check for myla log data file name to analyze tool usage data, later linked to student course data\n",
    "    elif 'myla_event_log' in file_path and 'grade' not in file_path :\n",
    "        _, res = dbx.files_download(file_path)\n",
    "        with io.BytesIO(res.content) as stream:\n",
    "            df = pd.read_csv(stream)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        year_code = file_path[int(file_path.find('.csv'))-4:int(file_path.find('.csv'))]\n",
    "        print(' - - - event log file')\n",
    "        df_term = set_term_code(file_path,year_code)\n",
    "#         print('Term is: ', df_term)\n",
    "        df['Term Code'] = df_term\n",
    "        df = df.rename({'id':'Click ID','timestamp':'Click Timestamp','action':'Module',\n",
    "                       'username':'Uniqname','course_id':'Canvas CID'}, axis='columns')\n",
    "        df['Canvas CID'] = df['Canvas CID']%1000000\n",
    "        df['Canvas CID'] = df['Canvas CID'].astype(str)\n",
    "        df['Click ID'] = df['Click ID'].astype(str)\n",
    "        df = df[['Click ID', 'Click Timestamp', 'Module', 'Uniqname', 'Canvas CID', 'Term Code']]\n",
    "        df_logs = pd.concat([df_logs,df])\n",
    "#         print(df.head(5))\n",
    "#         print(df_logs.columns)\n",
    "#         print(df_logs.head(5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(' - - - other file')\n",
    "        print(file_path)\n",
    "print('\\nBREAK')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cbd7fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_main = pd.merge(df_main,df_cmap,on='Canvas CName',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e6cce8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniqname</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Intl/Dom</th>\n",
       "      <th>Class Level</th>\n",
       "      <th>Cum GPA</th>\n",
       "      <th>Canvas CName</th>\n",
       "      <th>Term Code</th>\n",
       "      <th>Canvas CID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abdsul</td>\n",
       "      <td>Male</td>\n",
       "      <td>International</td>\n",
       "      <td>Grad Mastr</td>\n",
       "      <td>3.673</td>\n",
       "      <td>HMP 654 001 FA 2019</td>\n",
       "      <td>202010</td>\n",
       "      <td>317173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aileenz</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Grad Mastr</td>\n",
       "      <td>3.731</td>\n",
       "      <td>HMP 654 001 FA 2019</td>\n",
       "      <td>202010</td>\n",
       "      <td>317173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alexfox</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Grad Mastr</td>\n",
       "      <td>3.877</td>\n",
       "      <td>HMP 654 001 FA 2019</td>\n",
       "      <td>202010</td>\n",
       "      <td>317173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angiemm</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Grad Mastr</td>\n",
       "      <td>3.879</td>\n",
       "      <td>HMP 654 001 FA 2019</td>\n",
       "      <td>202010</td>\n",
       "      <td>317173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4719</th>\n",
       "      <td>vessecce</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>2.950</td>\n",
       "      <td>EECS 215 002 WN 2019</td>\n",
       "      <td>201920</td>\n",
       "      <td>268094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>xuanting</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Junior</td>\n",
       "      <td>3.606</td>\n",
       "      <td>EECS 215 002 WN 2019</td>\n",
       "      <td>201920</td>\n",
       "      <td>268094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>yunzen</td>\n",
       "      <td>Male</td>\n",
       "      <td>International</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>3.430</td>\n",
       "      <td>EECS 215 002 WN 2019</td>\n",
       "      <td>201920</td>\n",
       "      <td>268094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>ziyangji</td>\n",
       "      <td>Male</td>\n",
       "      <td>International</td>\n",
       "      <td>Junior</td>\n",
       "      <td>3.837</td>\n",
       "      <td>EECS 215 002 WN 2019</td>\n",
       "      <td>201920</td>\n",
       "      <td>268094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>zjustin</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Junior</td>\n",
       "      <td>3.739</td>\n",
       "      <td>EECS 215 002 WN 2019</td>\n",
       "      <td>201920</td>\n",
       "      <td>268094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4724 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Uniqname     Sex       Intl/Dom Class Level  Cum GPA  \\\n",
       "0          NaN     NaN            NaN         NaN      NaN   \n",
       "1       abdsul    Male  International  Grad Mastr    3.673   \n",
       "2      aileenz  Female       Domestic  Grad Mastr    3.731   \n",
       "3      alexfox    Male       Domestic  Grad Mastr    3.877   \n",
       "4      angiemm  Female       Domestic  Grad Mastr    3.879   \n",
       "...        ...     ...            ...         ...      ...   \n",
       "4719  vessecce    Male       Domestic   Sophomore    2.950   \n",
       "4720  xuanting    Male       Domestic      Junior    3.606   \n",
       "4721    yunzen    Male  International   Sophomore    3.430   \n",
       "4722  ziyangji    Male  International      Junior    3.837   \n",
       "4723   zjustin    Male       Domestic      Junior    3.739   \n",
       "\n",
       "              Canvas CName Term Code Canvas CID  \n",
       "0                      NaN       NaN        NaN  \n",
       "1      HMP 654 001 FA 2019    202010     317173  \n",
       "2      HMP 654 001 FA 2019    202010     317173  \n",
       "3      HMP 654 001 FA 2019    202010     317173  \n",
       "4      HMP 654 001 FA 2019    202010     317173  \n",
       "...                    ...       ...        ...  \n",
       "4719  EECS 215 002 WN 2019    201920     268094  \n",
       "4720  EECS 215 002 WN 2019    201920     268094  \n",
       "4721  EECS 215 002 WN 2019    201920     268094  \n",
       "4722  EECS 215 002 WN 2019    201920     268094  \n",
       "4723  EECS 215 002 WN 2019    201920     268094  \n",
       "\n",
       "[4724 rows x 8 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# print(df_main['Canvas CID_x'])\n",
    "# df_main['Canvas CID_x'] + df_main['Canvas CID_y']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_main['Canvas CID'] = np.where(\n",
    "    df_main['Canvas CID_y'].isna(), df_main['Canvas CID_x'], \n",
    "     np.where(df_main['Canvas CID_y'].notna(),  df_main['Canvas CID_y'], 'Unknown')\n",
    ")\n",
    "df_main.drop(columns=['Canvas CID_y','Canvas CID_x'],inplace=True)\n",
    "df_main\n",
    "\n",
    "# df_main = df_main.join(df_cmap,on='Canvas CName', how='left', lsuffix='', rsuffix=' map')\n",
    "# df_main.to_clipboard()\n",
    "# print(df_main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f9462ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 324902\n",
    "# 341239\n",
    "df_grades['Uniqname'] = df_grades['Uniqname'].apply(lambda x:x.split(\"@\")[0])\n",
    "\n",
    "grades_names = df_grades['Uniqname'].unique()\n",
    "grades_names = set(grades_names)\n",
    "# print(grades_names)\n",
    "main_names = df_main['Uniqname'].unique()\n",
    "main_names = set(main_names)\n",
    "# print(main_names)\n",
    "combo_names = main_names.union(grades_names)\n",
    "combo_names = pd.DataFrame(combo_names)\n",
    "combo_names.to_clipboard()\n",
    "# print(len(main_names.difference(grades_names)))\n",
    "# print(len(grades_names.difference(main_names)))\n",
    "\n",
    "# main\n",
    "# grades_names\n",
    "# combo_names = pd.merge(main_names,grades_names,how='left',indicator=True)\n",
    "# combo_names.to_clipboard()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5b0314ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mw/lvyghwsj075fxfp7plz61yvh0000gn/T/ipykernel_40500/1760312260.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_grades\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_grades\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_smap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Uniqname'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 106\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1254\u001b[0m                     \u001b[0minferred_right\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minferred_left\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 ):\n\u001b[0;32m-> 1256\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0;31m# datetimelikes must match exactly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "df_grades = pd.merge(df_grades,df_smap,on='Uniqname',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7b3d67d0-b855-4f98-8a5e-b6993734e34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_main: 3929\n",
      "df_grades: 3865\n",
      "df_logs: 1732\n",
      "df_smap: 3961\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_term_desc(term_code) :\n",
    "    term_type = int(term_code)%100\n",
    "    year = math.trunc(int(term_code)/100)\n",
    "    if term_type == 10 :\n",
    "        year -= 1\n",
    "        term_typ_desc = 'Fall'\n",
    "    else :\n",
    "        term_typ_desc = 'Winter'\n",
    "    term_desc = term_typ_desc + ' ' + str(year)\n",
    "    return(term_desc)\n",
    "\n",
    "\n",
    "\n",
    "df_main = df_main.dropna()\n",
    "df_main = df_main.drop_duplicates()\n",
    "df_main = df_main[df_main['Canvas CID'] != '322656']\n",
    "\n",
    "df_logs = df_logs.dropna()\n",
    "df_logs = df_logs.drop_duplicates()\n",
    "df_logs = df_logs[df_logs['Canvas CID'] != '322656']\n",
    "\n",
    "\n",
    "df_grades = df_grades.dropna()\n",
    "df_grades = df_grades.drop_duplicates()\n",
    "df_grades = df_grades[df_grades['Canvas CID'] != '322656']\n",
    "\n",
    "\n",
    "df_grades = df_grades[['Canvas CID', 'Uniqname', 'Final Grade', 'Term Code']]\n",
    "\n",
    "df_grades['Course GPA'] = ((df_grades['Final Grade'].astype(int)/10-5).astype(int) +\n",
    "                              (((df_grades['Final Grade'].astype(int)%10+.5)*.3).astype(int)-1)*.33)\n",
    "\n",
    "df_grades['Course GPA'] = df_grades['Course GPA'].clip(0,4)\n",
    "# print(df_main.columns)\n",
    "# print(df_main.head(6))\n",
    "\n",
    "# print(df_grades)\n",
    "# print(df_grades.columns)\n",
    "# print(df_grades[['Course GPA']].describe())\n",
    "\n",
    "df_main_w19 = df_main[df_main['Term Code'] == '201920']\n",
    "\n",
    "# print(df_main_w19['Canvas CName'].unique())\n",
    "\n",
    "# this command joins the main df with the course map df, so course ID may be consistent\n",
    "# df_combo = df_main.join(df_cmap.set_index('Temp CID'), on='Temp CID', how='left', lsuffix='', rsuffix=' map')\n",
    "\n",
    "# df_smap.to_clipboard()\n",
    "# df_cmap.to_clipboard()\n",
    "\n",
    "# df_grades.to_clipboard()\n",
    "# df_main.to_clipboard()\n",
    "# df_logs.to_clipboard()\n",
    "\n",
    "\n",
    "n_stud = df_main['Uniqname'].nunique()\n",
    "print('df_main:',n_stud)\n",
    "n_stud = df_grades['Uniqname'].nunique()\n",
    "print('df_grades:',n_stud)\n",
    "n_stud = df_logs['Uniqname'].nunique()\n",
    "print('df_logs:',n_stud)\n",
    "n_stud = df_smap['Uniqname'].nunique()\n",
    "print('df_smap:',n_stud)\n",
    "# print(df_main)\n",
    "# print(df_logs)\n",
    "\n",
    "\n",
    "n_stud_course_grades = df_grades.groupby(['Term Code','Canvas CID']).nunique()['Uniqname']\n",
    "n_stud_course_main = df_main.groupby(['Term Code','Canvas CID']).nunique()['Uniqname']\n",
    "n_stud_course_logs = df_logs.groupby(['Term Code']).nunique()['Uniqname']\n",
    "\n",
    "\n",
    "distinct_uniqnames = df_main.Uniqname.unique()\n",
    "distinct_uniqnames = pd.DataFrame(distinct_uniqnames)\n",
    "# distinct_uniqnames = distinct_uniqnames.to_frame()\n",
    "# distinct_uniqnames.to_clipboard()\n",
    "\n",
    "\n",
    "\n",
    "n_stud_course_main.to_clipboard()\n",
    "# n_stud_course_logs.to_clipboard()\n",
    "# n_stud_course_grades.to_clipboard()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "81398cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniqname</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Intl/Dom</th>\n",
       "      <th>Class Level</th>\n",
       "      <th>Cum GPA</th>\n",
       "      <th>Canvas CName</th>\n",
       "      <th>Term Code</th>\n",
       "      <th>Canvas CID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abdsul</td>\n",
       "      <td>Male</td>\n",
       "      <td>International</td>\n",
       "      <td>Grad Mastr</td>\n",
       "      <td>3.673</td>\n",
       "      <td>HMP 654 001 FA 2019</td>\n",
       "      <td>202010</td>\n",
       "      <td>317173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aileenz</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Grad Mastr</td>\n",
       "      <td>3.731</td>\n",
       "      <td>HMP 654 001 FA 2019</td>\n",
       "      <td>202010</td>\n",
       "      <td>317173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alexfox</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Grad Mastr</td>\n",
       "      <td>3.877</td>\n",
       "      <td>HMP 654 001 FA 2019</td>\n",
       "      <td>202010</td>\n",
       "      <td>317173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angiemm</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Grad Mastr</td>\n",
       "      <td>3.879</td>\n",
       "      <td>HMP 654 001 FA 2019</td>\n",
       "      <td>202010</td>\n",
       "      <td>317173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>asbrandt</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Grad Mastr</td>\n",
       "      <td>3.770</td>\n",
       "      <td>HMP 654 001 FA 2019</td>\n",
       "      <td>202010</td>\n",
       "      <td>317173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4583</th>\n",
       "      <td>vessecce</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>2.950</td>\n",
       "      <td>EECS 215 002 WN 2019</td>\n",
       "      <td>201920</td>\n",
       "      <td>268094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>xuanting</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Junior</td>\n",
       "      <td>3.606</td>\n",
       "      <td>EECS 215 002 WN 2019</td>\n",
       "      <td>201920</td>\n",
       "      <td>268094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>yunzen</td>\n",
       "      <td>Male</td>\n",
       "      <td>International</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>3.430</td>\n",
       "      <td>EECS 215 002 WN 2019</td>\n",
       "      <td>201920</td>\n",
       "      <td>268094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>ziyangji</td>\n",
       "      <td>Male</td>\n",
       "      <td>International</td>\n",
       "      <td>Junior</td>\n",
       "      <td>3.837</td>\n",
       "      <td>EECS 215 002 WN 2019</td>\n",
       "      <td>201920</td>\n",
       "      <td>268094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>zjustin</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Junior</td>\n",
       "      <td>3.739</td>\n",
       "      <td>EECS 215 002 WN 2019</td>\n",
       "      <td>201920</td>\n",
       "      <td>268094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4587 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Uniqname     Sex       Intl/Dom Class Level  Cum GPA  \\\n",
       "1       abdsul    Male  International  Grad Mastr    3.673   \n",
       "2      aileenz  Female       Domestic  Grad Mastr    3.731   \n",
       "3      alexfox    Male       Domestic  Grad Mastr    3.877   \n",
       "4      angiemm  Female       Domestic  Grad Mastr    3.879   \n",
       "5     asbrandt    Male       Domestic  Grad Mastr    3.770   \n",
       "...        ...     ...            ...         ...      ...   \n",
       "4583  vessecce    Male       Domestic   Sophomore    2.950   \n",
       "4584  xuanting    Male       Domestic      Junior    3.606   \n",
       "4585    yunzen    Male  International   Sophomore    3.430   \n",
       "4586  ziyangji    Male  International      Junior    3.837   \n",
       "4587   zjustin    Male       Domestic      Junior    3.739   \n",
       "\n",
       "              Canvas CName Term Code Canvas CID  \n",
       "1      HMP 654 001 FA 2019    202010     317173  \n",
       "2      HMP 654 001 FA 2019    202010     317173  \n",
       "3      HMP 654 001 FA 2019    202010     317173  \n",
       "4      HMP 654 001 FA 2019    202010     317173  \n",
       "5      HMP 654 001 FA 2019    202010     317173  \n",
       "...                    ...       ...        ...  \n",
       "4583  EECS 215 002 WN 2019    201920     268094  \n",
       "4584  EECS 215 002 WN 2019    201920     268094  \n",
       "4585  EECS 215 002 WN 2019    201920     268094  \n",
       "4586  EECS 215 002 WN 2019    201920     268094  \n",
       "4587  EECS 215 002 WN 2019    201920     268094  \n",
       "\n",
       "[4587 rows x 8 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "220575bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# print(df_logs.head(6))\n",
    "# reduce to 6 columns, sort, and remove canvas course id 322656\n",
    "df_logs = df_logs[['Term Code','Uniqname','Click Timestamp', 'Canvas CID','Module','Click ID']]\n",
    "df_logs = df_logs.sort_values(by=['Term Code','Uniqname','Click Timestamp'])\n",
    "df_logs['Module'] = df_logs['Module'].replace({'VIEW_FILE_ACCESS': 'VFA',\n",
    "                                                'VIEW_GRADE_DISTRIBUTION': 'VGD',\n",
    "                                                'VIEW_ASSIGNMENT_PLANNING':'VAP',\n",
    "                                                'VIEW_SET_DEFAULT':'VSD',\n",
    "                                                'VIEW_RESOURCE_ACCESS':'VRA',\n",
    "                                                'VIEW_ASSIGNMENT_PLANNING_WITH_GOAL_SETTING':'VAP-GS'\n",
    "                                              })\n",
    "# print(df_logs['Module'].unique())\n",
    "df_logs['Click Date'] = pd.to_datetime(df_logs['Click Timestamp']).dt.date\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# - - - - - - Dates for Term Start and End - - - - - - - \n",
    "\n",
    "# Winter 2019 - Start: 2019-01-09      End: 2019-05-02\n",
    "# Fall 2019   - Start: 2019-09-03      End: 2019-12-20\n",
    "# Winter 2020 - Start: 2020-01-08      End: 2020-04-30\n",
    "# Fall 2020   - Start: 2020-08-31      End: 2020-12-18\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "df_logs['Term Start Date'] = df_logs['Term Code'].replace({\n",
    "                                                '201920': '2019-01-09',\n",
    "                                                '202010': '2019-09-03',\n",
    "                                                '202020': '2020-01-08',\n",
    "                                                '202110': '2020-08-31'\n",
    "                                              })\n",
    "df_logs['Term Start Date'] = df_logs['Term Start Date'].apply(pd.to_datetime).dt.date\n",
    "df_logs['Term End Date'] = df_logs['Term Code'].replace({\n",
    "                                                '201920': '2019-05-02',\n",
    "                                                '202010': '2019-12-20',\n",
    "                                                '202020': '2020-04-30',\n",
    "                                                '202110': '2020-12-18'\n",
    "                                              })\n",
    "df_logs['Term End Date'] = df_logs['Term End Date'].apply(pd.to_datetime).dt.date\n",
    "df_logs['Term Length'] = (df_logs['Term End Date']-df_logs['Term Start Date']).dt.days\n",
    "# print(df_logs.columns)\n",
    "# print(df_logs.head(6))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dbc0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_click_times = df_logs[['Term Code','Term Start Date','Term End Date','Term Length','Click Date','Click ID']]\n",
    "df_click_times = df_click_times.sort_values(by=['Term Code','Click Date'])\n",
    "df_click_times['Days from Start'] = (df_click_times['Click Date']-df_click_times['Term Start Date']).dt.days\n",
    "# df_click_times['Click Week'] = pd.to_datetime(df_click_times['Click Date']).dt.isocalendar().week\n",
    "# print(df_click_times.columns)\n",
    "# print(df_click_times.head(6))\n",
    "df_click_times = df_click_times[['Term Code','Days from Start','Term Length']]\n",
    "# print(df_click_times)\n",
    "# print(df_click_times['Term Code'].unique())\n",
    "\n",
    "\n",
    "# print(type(df_click_times['Click Date']))\n",
    "\n",
    "\n",
    "\n",
    "# for each_term in df_click_times['Term Code'].unique() :\n",
    "#     print(each_term)\n",
    "#     print(get_term_desc(each_term))\n",
    "#     df_click_times_subset = df_click_times[df_click_times['Term Code'] == each_term]\n",
    "# #     min_date = df_click_times_subset['Days from Start']\n",
    "# #     df_click_times_subset = df_click_times_subset['Term Code','Days from Start','Term Length']\n",
    "#     print('min date:')\n",
    "#     print(df_click_times_subset)\n",
    "    \n",
    "    \n",
    "#     fig, axs = plt.subplots(figsize=(8, 1))\n",
    "#     day_clicks = df_click_times_subset.groupby(['Click Week']).nunique()['Click ID'].plot(\n",
    "#         kind='bar', rot=0, ax=axs\n",
    "#     )\n",
    "    \n",
    "#     plt.xlabel(get_term_desc(each_term));\n",
    "\n",
    "#     print(day_clicks)\n",
    "#     print(each_term)\n",
    "\n",
    "\n",
    "# # using subplot function and creating plot one\n",
    "# plt.subplot(1, 2, 1)  # row 1, column 2, count 1\n",
    "# plt.plot(x, y_1, 'r', linewidth=5, linestyle=':')\n",
    "# plt.title('FIRST PLOT')\n",
    "# plt.xlabel('x-axis')\n",
    "# plt.ylabel('y-axis')\n",
    " \n",
    "# # using subplot function and creating plot two\n",
    "# # row 1, column 2, count 2\n",
    "# plt.subplot(1, 2, 2)\n",
    " \n",
    "# # g is gor green color\n",
    "# plt.plot(x, y_2, 'g', linewidth=5)\n",
    "# plt.title('SECOND PLOT')\n",
    "# plt.xlabel('x-axis')\n",
    "# plt.ylabel('y-axis')\n",
    " \n",
    "# # space between the plots\n",
    "# plt.tight_layout(4)\n",
    " \n",
    "# # show plot\n",
    "# plt.show()\n",
    "\n",
    "# df_logs_combo = df_logs.join(df_cmap.set_index('Temp CID'),on='Temp CID', how='left', lsuffix='', rsuffix=' map')\n",
    "# df_logs_combo = df_logs_combo[df_logs_combo['Canvas CID'] != '322656']\n",
    "\n",
    "# df_logs_combo = df_logs_combo[['Term Code','Temp CID','Canvas CIDF','Campus ID']]\n",
    "# print(df_log_combo.head(5))\n",
    "\n",
    "# creates new column, showing Canvas ID when available, and showing Course ID when not (for Fall 2020 file)\n",
    "# df_combo['Canvas CIDF'] = np.where(\n",
    "#     df_combo['Canvas CID'].isna(), df_combo['Temp CID'], \n",
    "#      np.where(df_combo['Canvas CID'].notna(),  df_combo['Canvas CID'], 'Unknown')\n",
    "# )\n",
    "\n",
    "# reduce to 4 columns, sort, and remove canvas course id 322656\n",
    "# df_combo = df_combo[['Term Code','Temp CID','Canvas CIDF','Campus ID']]\n",
    "# df_combo = df_combo.sort_values(by=['Term Code','Canvas CIDF','Campus ID'])\n",
    "# df_combo = df_combo[df_combo['Canvas CIDF'] != '322656']\n",
    "\n",
    "# count students per course per term\n",
    "# enrollments = df_combo.groupby(['Term Code','Canvas CIDF','Temp CID']).count()['Campus ID']\n",
    "\n",
    "# myla_users = df_logs_combo.groupby(['Term Code','Canvas CID']).nunique()['Temp SID']\n",
    "# myla_users = df_logs.groupby(['Term Code','Temp CID']).nunique()['Temp SID']\n",
    "\n",
    "# print(enrollments.head(5))\n",
    "# print(df_combo.columns)\n",
    "# print(df_combo.head(5))\n",
    "\n",
    "\n",
    "# print(df_logs.head(5))\n",
    "# print(myla_users.head(5))\n",
    "\n",
    "\n",
    "\n",
    "# to print dataframe as csv out to file on desktop, use following code\n",
    "# out_file_path = Path('/Users/sticker/Desktop/myla_outputs/out.csv')\n",
    "# out_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# course_counts.to_csv(out_file_path)\n",
    "# df_main.to_csv(out_file_path)\n",
    "# df_combo.to_csv(out_file_path)\n",
    "# df_cmap.to_csv(out_file_path)\n",
    "# enrollments.to_csv(out_file_path)\n",
    "# myla_users.to_csv(out_file_path)\n",
    "\n",
    "\n",
    "\n",
    "#optional code bits\n",
    "\n",
    "# this lists every unique value for the indicated column\n",
    "# course_list = df_main.CanvasCourseID_long.unique()\n",
    "# this counts every row for each value in the indicated column\n",
    "# course_counts = df_main[['Term Code','Course ID']].value_counts()\n",
    "\n",
    "# this lists every unique value for the indicated column\n",
    "# course_term_list = df_main.CanvasCourseID_long.unique()\n",
    "# this counts every row for each value in the indicated column\n",
    "# course_term_counts = df_main[['Term Code']].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "# for col in df_main :\n",
    "#     na_counts = df_main[col].isnull().sum()\n",
    "#     print(col, \" \",na_counts)\n",
    "\n",
    "# print(df_main.nunique())\n",
    "# print(course_list)\n",
    "# print(course_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
